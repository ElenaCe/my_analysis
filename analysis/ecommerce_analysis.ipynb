{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame:\n",
      "                event_time event_type  product_id          category_id  \\\n",
      "0  2019-11-01 00:00:00 UTC       view     1003461  2053013555631882655   \n",
      "1  2019-11-01 00:00:00 UTC       view     5000088  2053013566100866035   \n",
      "2  2019-11-01 00:00:01 UTC       view    17302664  2053013553853497655   \n",
      "3  2019-11-01 00:00:01 UTC       view     3601530  2053013563810775923   \n",
      "4  2019-11-01 00:00:01 UTC       view     1004775  2053013555631882655   \n",
      "\n",
      "               category_code   brand   price    user_id  \\\n",
      "0     electronics.smartphone  xiaomi  489.07  520088904   \n",
      "1  appliances.sewing_machine  janome  293.65  530496790   \n",
      "2                        NaN   creed   28.31  561587266   \n",
      "3  appliances.kitchen.washer      lg  712.87  518085591   \n",
      "4     electronics.smartphone  xiaomi  183.27  558856683   \n",
      "\n",
      "                           user_session     month  \n",
      "0  4d3b30da-a5e4-49df-b1a8-ba5943f1dd33  November  \n",
      "1  8e5f4f83-366c-4f70-860e-ca7417414283  November  \n",
      "2  755422e7-9040-477b-9bd2-6a6e8fd97387  November  \n",
      "3  3bfb58cd-7892-48cc-8020-2f17e6de6e7f  November  \n",
      "4  313628f1-68b8-460d-84f6-cec7a8796ef2  November  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the paths to the CSV files\n",
    "nov_csv_path = '/Users/elenacellitti/Downloads/ecommerce_data/ecommerce_nov_19.csv'\n",
    "oct_csv_path = '/Users/elenacellitti/Downloads/ecommerce_data/ecommerce_oct_19.csv'\n",
    "\n",
    "# Load the CSV files into pandas DataFrames\n",
    "nov_df = pd.read_csv(nov_csv_path)\n",
    "oct_df = pd.read_csv(oct_csv_path)\n",
    "\n",
    "# Extract month from the \"event_time\" column\n",
    "nov_df['month'] = pd.to_datetime(nov_df['event_time']).dt.month_name()\n",
    "oct_df['month'] = pd.to_datetime(oct_df['event_time']).dt.month_name()\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "combined_df = pd.concat([nov_df, oct_df], ignore_index=True)\n",
    "\n",
    "# Display the first few rows of the combined DataFrame\n",
    "print(\"Combined DataFrame:\")\n",
    "print(combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in the DataFrame:\n",
      "event_time              0\n",
      "event_type              0\n",
      "product_id              0\n",
      "category_id             0\n",
      "category_code    35413780\n",
      "brand            15341158\n",
      "price                   0\n",
      "user_id                 0\n",
      "user_session           12\n",
      "month                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the DataFrame\n",
    "# print(\"First few rows of the DataFrame:\")\n",
    "# print(combined_df.head())\n",
    "\n",
    "# # Get a concise summary of the DataFrame including data types and missing values\n",
    "# print(\"\\nSummary of the DataFrame:\")\n",
    "# print(combined_df.info())\n",
    "\n",
    "# Check for missing values in the DataFrame\n",
    "print(\"\\nMissing values in the DataFrame:\")\n",
    "print(combined_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrame after dropping columns:\n",
      "                event_time event_type  product_id          category_id  \\\n",
      "0  2019-11-01 00:00:00 UTC       view     1003461  2053013555631882655   \n",
      "1  2019-11-01 00:00:00 UTC       view     5000088  2053013566100866035   \n",
      "2  2019-11-01 00:00:01 UTC       view    17302664  2053013553853497655   \n",
      "3  2019-11-01 00:00:01 UTC       view     3601530  2053013563810775923   \n",
      "4  2019-11-01 00:00:01 UTC       view     1004775  2053013555631882655   \n",
      "\n",
      "    price    user_id                          user_session     month  \n",
      "0  489.07  520088904  4d3b30da-a5e4-49df-b1a8-ba5943f1dd33  November  \n",
      "1  293.65  530496790  8e5f4f83-366c-4f70-860e-ca7417414283  November  \n",
      "2   28.31  561587266  755422e7-9040-477b-9bd2-6a6e8fd97387  November  \n",
      "3  712.87  518085591  3bfb58cd-7892-48cc-8020-2f17e6de6e7f  November  \n",
      "4  183.27  558856683  313628f1-68b8-460d-84f6-cec7a8796ef2  November  \n"
     ]
    }
   ],
   "source": [
    "# A lot of null values were found for category_code and brand that aren't useful for my analysis. For this reason I'm dropping these columns, also as it makes things easier \n",
    "\n",
    "# Drop columns with a lot of null values\n",
    "combined_df.drop(columns=['category_code', 'brand'], inplace=True)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(\"Updated DataFrame after dropping columns:\")\n",
    "print(combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique event types:\n",
      "['view' 'cart' 'purchase']\n"
     ]
    }
   ],
   "source": [
    "# To understand what events I have, this will print a unique list of them\n",
    "# Get unique values of the 'event_type' column\n",
    "event_types = combined_df['event_type'].unique()\n",
    "\n",
    "# Display the unique event types\n",
    "print(\"Unique event types:\")\n",
    "print(event_types)\n",
    "\n",
    "# Unique event types: ['view' 'cart' 'purchase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Grouping and aggregating\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m grouped_df \u001b[38;5;241m=\u001b[39m \u001b[43mcombined_df\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_time\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_type\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39magg(\n\u001b[1;32m      3\u001b[0m     count_total\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mNamedAgg(column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_type\u001b[39m\u001b[38;5;124m'\u001b[39m, aggfunc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      4\u001b[0m     count_user\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mNamedAgg(column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m, aggfunc\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mSeries\u001b[38;5;241m.\u001b[39mnunique)\n\u001b[1;32m      5\u001b[0m )\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Pivot the dataframe to reshape it\u001b[39;00m\n\u001b[1;32m      8\u001b[0m final_df \u001b[38;5;241m=\u001b[39m grouped_df\u001b[38;5;241m.\u001b[39mpivot_table(\n\u001b[1;32m      9\u001b[0m     index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_time\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_id\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     10\u001b[0m     columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_type\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m     values\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount_total\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount_user\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     12\u001b[0m     fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     13\u001b[0m )\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'combined_df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Grouping and aggregating\n",
    "grouped_df = combined_df.groupby(['event_time', 'product_id', 'event_type']).agg(\n",
    "    count_total=pd.NamedAgg(column='event_type', aggfunc='count'),\n",
    "    count_user=pd.NamedAgg(column='user_id', aggfunc=pd.Series.nunique)\n",
    ").reset_index()\n",
    "\n",
    "# Pivot the dataframe to reshape it\n",
    "final_df = grouped_df.pivot_table(\n",
    "    index=['event_time', 'product_id'],\n",
    "    columns='event_type',\n",
    "    values=['count_total', 'count_user'],\n",
    "    fill_value=0\n",
    ").reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "final_df.columns = ['event_time', 'product_id', \n",
    "                    'count_total_cart', 'count_total_purchase', 'count_total_view', \n",
    "                    'count_user_cart', 'count_user_purchase', 'count_user_view']\n",
    "\n",
    "print(final_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
